This module constructs a data pipeline that fetches a CSV file from a URL, loads it into a pandas DataFrame, and then ingests the data into a PostgreSQL database.

.. note::
   The data is appended on each pipeline run. This means that new data is added to the existing table without removing the old data.

Dataframe Pipeline
====================

This pipeline demonstrates loading data from a pandas DataFrame into a PostgreSQL datawarehouse. It fetches a CSV file from a remote URL, reads it into a DataFrame, and loads it into a single table.

Pipeline Components
-------------------

- **Data Source**: A CSV file hosted at `https://people.sc.fsu.edu/~jburkardt/data/csv/hw_200.csv`.
- **ETL Tool**: `dlt` (data load tool) Python library.
- **Data Manipulation**: `pandas` library for creating a DataFrame.
- **Destination**: A PostgreSQL database instance.

Workflow
--------

The pipeline executes the following steps:

1.  **Initialization**: A `dlt` pipeline is initialized with the name `dataframe_pipeline`, a `postgres` destination, and the dataset name `dataframe_data`.
2.  **Data Fetching**: The `fetch_dataframe_data` resource fetches the CSV file from the specified URL.
3.  **DataFrame Creation**: The fetched data is read into a pandas DataFrame.
4.  **Table Creation**: `dlt` creates a table named `dataframe_table` in the `dataframe_data` schema.
5.  **Data Insertion**: The data from the DataFrame is inserted into the `dataframe_table`.
6.  **Termination**: The pipeline run finishes, and load information is printed to the console.

Workflow Diagram
~~~~~~~~~~~~~~~~

.. mermaid::
   :name: dataframe_pipeline_workflow

   graph TD
      A[Start] --> B{Initialize dlt Pipeline};
      B --> C{Call fetch_dataframe_data resource};
      C --> D[Fetch CSV from URL];
      D --> E[Create pandas DataFrame];
      E --> F{Load data into PostgreSQL};
      subgraph "PostgreSQL (dataframe_data schema)"
         F --> G[dataframe_table table]
      end
      G --> H[End]

Data Schema
-----------

The pipeline creates the following table in the `dataframe_data` schema in the PostgreSQL database:

- `dataframe_table`

The columns in the table are inferred by `dlt` from the pandas DataFrame. `dlt` also adds its own metadata columns (`_dlt_load_id`, `_dlt_id`) for internal tracking.

Technical Documentation
-----------------------
.. note:: Following section is auto-generated by `sphinx-autodoc-typehints` extension.

Entry point for the dataframe pipeline:

.. automodule:: dataframe_pipeline
   :members:

